p <- ggplot(data=black, aes(x=Product.Type)) +
labs(title = "Blackwell product purchase frequency") +
geom_bar()
p
![Picture]("C:/Users/David/Desktop/elctronidex.png")
!["Picture"]("C:/Users/David/Desktop/elctronidex.png")
!["Picture"](C:/Users/David/Desktop/elctronidex.png)
![Picture](C:/Users/David/Desktop/elctronidex.png)
![Picture](C:/Users/David/Google Drive/Ubiqum/)
![Picture.](C:/Users/David/Google Drive/Ubiqum/electrodinex.png)
knitr::include_graphics("C:/Users/David/Google Drive/Ubiqum/electrodinex.png")
knitr::include_graphics("C:/Users/David/Google Drive/Ubiqum/electrodinex.png")
knitr::include_graphics("C:/Users/David/Google Drive/Ubiqum/electro")
p
dataHigh <- data[size(data)<=10& size(data)>0]
hist(size(dataHigh))
hist((size(data))) #histo frecuencia del numero de productos por transaccion#
dataHigh<-data[size(data)<=10& size(data)>0]
hist(size(dataHigh))
dataHigh <- data[size(data) <= 5 & size(data) > 0]
hist(size(dataHigh))
rules = apriori(data = data, parameter = list(support = 0.01, confidence = 0.1), appearance = list(lhs = "iMac"))
inspect(head(sort(rules, by="lift"),5))
plot(rules, method = "graph")
inspect(head(sort(rules, by="lift"),5))
inspect(head(sort(rules, by="lift"),10))
inspect(head(sort(rules, by="lift"),10))
itemFrequencyPlot(dat, topN=10) #hay que indicarle un top o no puede plotear#
itemFrequencyPlot(data, topN=10) #hay que indicarle un top o no puede plotear#
itemFrequencyPlot(data, topN=10) #hay que indicarle un top o no puede plotear#
plot(rules, method = "graph")
plot(sort(rules, by="confidence")[1:10], method = "graph") #### interactivo para ver lift y support#
plot(sort(rules, by="confidence")[1:10], method = "graph", engine="interactive") #### interactivo para ver lift y support#
plot(sort(rules, by="confidence")[1:10], method = "graph", engine="interactive") #### interactivo para ver lift y support#
plot(sort(rules, by="confidence")[1:10], method = "graph") #### interactivo para ver lift y support#
plot(sort(rules, by="confidence")[1:5], method = "graph") #### interactivo para ver lift y support#
plot(sort(rules, by="confidence")[1:5], method = "graph", engine="interactive") #### interactivo para ver lift y support#
inspect(head(sort(rules, by="lift"),10))
rm(list = ls())
```{r include=FALSE}
library(arules)
library(arulesViz)
library(dplyr)
library(ggplot2)
library(arules)
library(arulesViz)
library(dplyr)
library(ggplot2)
data = read.transactions("C:/Users/David/Google Drive/Ubiqum/5_MBA/transactions.csv",
format = "basket",
sep = ",",
rm.duplicates = T,
encoding = "unknown")
black = read.csv("C:/Users/David/Google Drive/Ubiqum/1_Blackwell/Regression Project/Data/existingProductAttributes.csv")
dataHigh <- data[size(data) <= 5 & size(data) > 0]
dataLow<-data[size(data)>5]
rules = apriori(data = data, parameter = list(support = 0.01, confidence = 0.1), appearance = list(lhs = "iMac"))
inspect(head(sort(rules, by="lift"),10))
inspect(head(sort(rules, by="lift"),10))
plot(rules, method = "graph")
inspect(head(sort(rules, by="lift"),10))
inspect(head(sort(rules, by="confidence"),10))
rules = apriori(data = data, parameter = list(support = 0.01, confidence = 0.1, minlen = 2), appearance = list(lhs = "iMac"))
inspect(head(sort(rules, by="confidence"),10))
inspect(head(sort(rules, by="confidence"),5))
rules = apriori(data = data, parameter = list(support = 0.01, confidence = 0.1, minlen = 2))
inspect(head(sort(rules, by="confidence"),5))
plot(rules, method = "graph")
rules = apriori(data = data, parameter = list(support = 0.01, confidence = 0.1, minlen = 2))
inspect(head(sort(rules, by="confidence"),5))
rules.generic = apriori(data = data, parameter = list(support = 0.01, confidence = 0.5, minlen = 2))
inspect(head(sort(rules, by="confidence"),5))
summary(rules)
plot(rules.generic, method = "graph")
inspect(head(sort(rules, by="confidence"),5))
rhs.product<-categorias[categorias %ni% c("iMac", "HP Laptop")]
products <- levels(data@itemInfo$labels)
rhs.product <- products[products %ni% c("iMac", "HP Laptop")]
"%ni%" = Negate("%in%")
products <- levels(data@itemInfo$labels)
rhs.product <- products[products %ni% c("iMac", "HP Laptop")]
data@itemInfo$labels
levels(data@itemInfo$labels)
c(data@itemInfo$labels)
products <- c(data@itemInfo$labels)
levels(data)
levels(data@itemInfo)
rhs.product <- products[products %ni% c("iMac", "HP Laptop")]
rules.product = apriori(data = data, parameter = list(support = 0.01, confidence = 0.5, minlen = 2), appearance = list(rhs = rhs.product))
inspect(head(sort(rules, by="confidence"),5))
rules.product = apriori(data = data, parameter = list(support = 0.01, confidence = 0.1, minlen = 2), appearance = list(rhs = rhs.product))
inspect(head(sort(rules, by="confidence"),5))
rules.product = apriori(data = data, parameter = list(support = 0.01, confidence = 0.1, minlen = 2), appearance = list(rhs = products[products %ni% c("iMac", "HP Laptop")]))
inspect(head(sort(rules, by="confidence"),5))
head(rhs.product)
rules.product = apriori(data = data, parameter = list(support = 0.01, confidence = 0.1, minlen = 2), appearance = list(rhs = rhs.product))
inspect(head(sort(rules, by="confidence"),5))
inspect(head(sort(rules.product, by="confidence"),5))
########################
### apriori generico ###
rules.generic = apriori(data = data, parameter = list(support = 0.01, confidence = 0.5, minlen = 2))
plot(sort(rules.product, by="confidence")[1:5], method = "graph")
plot(sort(rules.product, by="confidence")[1:5], method = "graph", engine = "interactive")
plot(sort(rules.product, by="confidence")[1:5], method = "graph", engine = "interactive")
itemFrequencyPlot(data, topN=10) #hay que indicarle un top o no puede plotear#
itemFrequencyPlot(data, topN=10) #hay que indicarle un top o no puede plotear#
apriori(data)
brand.cat <- arules::aggregate(x = data, by = "brand")
rm(list = ls())
library(arules)
library(arulesViz)
library(dplyr)
library(ggplot2)
"%ni%" = Negate("%in%")
data = read.transactions("C:/Users/David/Google Drive/Ubiqum/5_MBA/transactions.csv",
format = "basket",
sep = ",",
rm.duplicates = T,
encoding = "unknown")
black = read.csv("C:/Users/David/Google Drive/Ubiqum/1_Blackwell/Regression Project/Data/existingProductAttributes.csv")
# setwd("C:/Users/pilar/Documents/Ubiqum/TASK2.4/task-2-4-basket-analysis-PCANALS")
# data = read.transactions("transactions.csv",
#                   format = "basket",
#                   sep = ",",
#                   rm.duplicates = T,
#                   encoding = "unknown")
dataHigh <- data[size(data) <= 5 & size(data) > 0]
dataLow<-data[size(data)>5]
########################
### apriori generico ###
########################
rules.generic = apriori(data = data, parameter = list(support = 0.01, confidence = 0.5, minlen = 2))
inspect(head(sort(rules.generic, by="confidence"),5))
###############################################################################################
### Top ventas que han de star a la izquierda, para conocer relaciones con otros productos ###
###############################################################################################
products <- c(data@itemInfo$labels)
rhs.product <- products[products %ni% c("iMac", "HP Laptop")]
rules.product = apriori(data = data, parameter = list(support = 0.01, confidence = 0.1, minlen = 2), appearance = list(rhs = rhs.product))
inspect(head(sort(rules.product, by="confidence"),5))
#plot(sort(rules.product, by="confidence")[1:5], method = "graph", engine = "interactive")
#### CAMBIAR NOMBRES DE ITEMS -  LABEL BRAND####
data@itemInfo$brand = data@itemInfo$labels
data@itemInfo$brand[grep(pattern = "^i[A-Z]", x = data@itemInfo$brand)] <- "Apple"
data@itemInfo$brand[grep(pattern = "^Apple", x = data@itemInfo$brand)] <- "Apple"
data@itemInfo$brand[grep(pattern = "^LG", x = data@itemInfo$brand)] <- "LG"
data@itemInfo$brand[grep(pattern = "^Acer", x = data@itemInfo$brand)] <- "Acer"
data@itemInfo$brand[grep(pattern = "^HP", x = data@itemInfo$brand)] <- "HP"
data@itemInfo$brand[grep(pattern = "^ASUS", x = data@itemInfo$brand)] <- "Asus"
data@itemInfo$brand[grep(pattern = "^Dell", x = data@itemInfo$brand)] <- "Dell"
data@itemInfo$brand[grep(pattern = "^Lenovo", x = data@itemInfo$brand)] <- "Lenovo"
data@itemInfo$brand[grep(pattern = "^CYBERPOWER", x = data@itemInfo$brand)] <- "Cyberpower"
data@itemInfo$brand[grep(pattern = "^Samsung", x = data@itemInfo$brand)] <- "Samsung"
data@itemInfo$brand[grep(pattern = "^Logit", x = data@itemInfo$brand)] <- "Logitech"
data@itemInfo$brand[grep(pattern = "^Microsoft", x = data@itemInfo$brand)] <- "Microsoft"
data@itemInfo$brand[grep(pattern = "^Rii", x = data@itemInfo$brand)] <- "Rii"
data@itemInfo$brand[grep(pattern = "^Alienware", x = data@itemInfo$brand)] <- "Alienware"
data@itemInfo$brand[data@itemInfo$brand %ni% c("Apple", "LG", "Acer", "HP", "Asus", "Dell", "Lenovo", "Cyberpower",
"Samsung", "Logitech", "Microsoft", "Rii", "Alienware")] <- "Others"
data@itemInfo$brand <- as.factor(data@itemInfo$brand)
brand.cat <- arules::aggregate(x = data, by = "brand")
rules.brand <- apriori(data = brand.cat,
#appearance = list(lhs= "Apple"),
parameter = list(support = 0.01, confidence = 0.5, minlen =2))
inspect(head(sort(rules.brand, by="confidence"),15))
str(data)
###########################
### GENERICO PARA APPLE ###
###########################
brand.cat <- arules::aggregate(x = data, by = "brand")
rules.apple <- apriori(data = brand.cat,
appearance = list(lhs= "Apple"),
parameter = list(support = 0.01, confidence = 0.5, minlen =2))
inspect(head(sort(rules.apple, by="confidence"),15))
inspect(head(sort(rules.apple, by="confidence"),15))
rules.apple <- apriori(data = brand.cat,
appearance = list(lhs= "Apple"),
parameter = list(support = 0.01, confidence = 0.3, minlen =2))
inspect(head(sort(rules.apple, by="confidence"),15))
###########################
### GENERICO PARA BRAND ###
###########################
brand.cat <- arules::aggregate(x = data, by = "brand")
rules.brand <- apriori(data = brand.cat,
#appearance = list(lhs= "Apple"),
parameter = list(support = 0.01, confidence = 0.5, minlen =2))
inspect(head(sort(rules.brand, by="confidence"),15))
plot(sort(x = rules.brand, by="confidence")[1:5],method="graph")
plot(sort(x = rules.brand, by="confidence")[1:5],method="graph", engine = "interactive")
plot(sort(x = rules.brand, by="confidence")[1:5],method="graph", engine = "interactive")
inspect(head(sort(rules.brand, by="confidence"),15))
plot(sort(x = rules.brand, by="confidence")[1:5],method="graph", engine = "interactive")
##########################
### GENERICO PRODUCTO ###
##########################
rules.generic = apriori(data = data, parameter = list(support = 0.01, confidence = 0.5, minlen = 2))
inspect(head(sort(rules.generic, by="confidence"),5))
##########################
### GENERICO PRODUCTO ###
##########################
rules.generic = apriori(data = data, parameter = list(support = 0.01, confidence = 0.5, minlen = 2))
inspect(head(sort(rules.generic, by="confidence"),10))
###############################################################################################
### Top ventas que han de star a la izquierda, para conocer relaciones con otros productos ###
###############################################################################################
products <- c(data@itemInfo$labels)
rhs.product <- products[products %ni% c("iMac", "HP Laptop")]
rules.product = apriori(data = data, parameter = list(support = 0.01, confidence = 0.1, minlen = 2), appearance = list(rhs = rhs.product))
inspect(head(sort(rules.product, by="confidence"),5))
#plot(sort(rules.product, by="confidence")[1:5], method = "graph", engine = "interactive")
itemFrequencyPlot(data, topN=10) #hay que indicarle un top o no puede plotear#
itemFrequencyPlot(data, topN=10) #hay que indicarle un top o no puede plotear#
existing = read.csv2("C:/Users/David/Google Drive/Ubiqum/4_Profitability2/existing.csv")
existing = read.csv2("C:/Users/David/Google Drive/Ubiqum/1_Blackwell/Regression Project/Data/existingProductAttributes.csv")
install.packages("wordcloud")
library(wordcloud)
wordcloud::textplot(existing$Product.Type.Product.Price.5.Star.Reviews.4.Star.Reviews.3.Star.Reviews.2.Star.Reviews.1.Star.Reviews.Positive.Service.Review.Negative.Service.Review.Would.consumer.recommend.product.Best.Sellers.Rank.Shipping.Weight..lbs..Product.Depth.Product.Width.Product.Height.Profit.margin.Volume)
wordcloud::textplot(existing$Product.Type)
wordcloud::textplot(table(existing$Product.Type))
wordcloud::wordcloud(existing)
install.packages("tm")
library(tm)
wordcloud::wordcloud(existing)
existing = read.csv2("C:/Users/David/Google Drive/Ubiqum/1_Blackwell/Regression Project/Data/existingProductAttributes.csv")
head(existing)
existing = read.csv("C:/Users/David/Google Drive/Ubiqum/1_Blackwell/Regression Project/Data/existingProductAttributes.csv")
head(existing)
wordcloud::wordcloud(existing$Product.Type)
wordcloud::wordcloud(words = existing$Product.Type, scale = c(2,2))
wordcloud::wordcloud(words = existing$Product.Type, scale = c(1,2))
wordcloud::wordcloud(words = existing$Product.Type, scale = c(1,5))
wordcloud::wordcloud(words = existing$Product.Type, scale = c(5,1))
table(existing$Product.Type)
wordcloud::wordcloud(words = existing$Product.Type, scale = c(5,1), max.words = length(table(existing$Product.Type)))
wordcloud::wordcloud(words = existing$Product.Type, max.words = length(table(existing$Product.Type)))
wordcloud::wordcloud(words = existing$Product.Type, max.words = length(table(existing$Product.Type)), random.color = F)
wordcloud::wordcloud(words = existing$Product.Type, max.words = length(table(existing$Product.Type)), random.color = T)
?wordcloud
wordcloud::wordcloud(words = existing$Product.Type, max.words = length(table(existing$Product.Type)), colors = "red")
wordcloud::wordcloud(words = existing$Product.Type, max.words = length(table(existing$Product.Type)),random.order = F, colors = "red")
wordcloud::wordcloud(words = existing$Product.Type, max.words = length(table(existing$Product.Type)),random.order = F, colors = "red, blue")
wordcloud::wordcloud(words = existing$Product.Type, max.words = length(table(existing$Product.Type)),
random.order = F,
colors = T)
wordcloud::wordcloud(words = existing$Product.Type, max.words = 5,
random.order = F,
colors = T)
wordcloud::wordcloud(words = existing$Product.Type, max.words = 10,
random.order = F,
colors = T)
wordcloud::wordcloud(words = existing$Product.Type, max.words = 20,
random.order = F,
colors = T)
levels(existing$Product.Type)
wordcloud::wordcloud(words = existing$Product.Type, max.words = 20,
random.order = F,
random.color = T,
colors = T)
wordcloud::wordcloud(words = existing$Product.Type, max.words = 12,
random.order = F,
random.color = T,
colors = T)
wordcloud::wordcloud(words = existing$Product.Type,
random.order = F,
random.color = T,
colors = T)
library(RColorBrewer)
wordcloud::wordcloud(words = existing$Product.Type,
random.order = F,
random.color = T,
colors = T)
readLines(existing$Product.Type)
readLines(c(existing$Product.Type))
as.character(existing$Product.Type)
vec = as.character(existing$Product.Type)
wordcloud::wordcloud(words = vec,
random.order = F,
random.color = T,
colors = T)
wordcloud::wordcloud(words = vec,
random.order = F,
random.color = T
)
wordcloud::wordcloud(words = vec
)
vec = Corpus(VectorSource(existing$Product.Type))
rm(list = ls())
existing = read.csv("C:/Users/David/Google Drive/Ubiqum/1_Blackwell/Regression Project/Data/existingProductAttributes.csv")
library(wordcloud)
library(tm)
library(RColorBrewer)
wordcloud::wordcloud(words = existing$Product.Type,
random.order = F,
random.color = T,
colors = T)
vec = Corpus(VectorSource(existing$Product.Type))
class(vec)
vec = tm_map(vec, content_transformer(tolower))
wordcloud::wordcloud(words = vec)
vec = tm_map(vec, content_transformer(PlainTextDocument))
View(vec)
wordcloud::wordcloud(words = vec)
wordcloud::wordcloud(words = vec, random.order = F)
rm(list = ls())
existing = read.csv("C:/Users/David/Google Drive/Ubiqum/1_Blackwell/Regression Project/Data/existingProductAttributes.csv")
library(wordcloud)
library(tm)
library(RColorBrewer)
vec = Corpus(VectorSource(existing$Product.Type))
wordcloud::wordcloud(words = vec, random.order = F)
vec = tm_map(vec, content_transformer(PlainTextDocument))
wordcloud::wordcloud(words = vec, random.order = F)
data(gapminder, package = "gapminder")
gg <- ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +
geom_point(aes(size = pop, frame = year, ids = country)) +
scale_x_log10()
ggplotly(gg)
install.packages("ggplot2")
library("ggplot2", lib.loc="Z:/R/library")
install.packages("plotly")
data(gapminder, package = "gapminder")
gg <- ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +
geom_point(aes(size = pop, frame = year, ids = country)) +
scale_x_log10()
ggplotly(gg)
install.packages("gapminder")
library("gapminder", lib.loc="Z:/R/library")
data(gapminder, package = "gapminder")
gg <- ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +
geom_point(aes(size = pop, frame = year, ids = country)) +
scale_x_log10()
ggplotly(gg)
library("plotly", lib.loc="Z:/R/library")
data(gapminder, package = "gapminder")
gg <- ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +
geom_point(aes(size = pop, frame = year, ids = country)) +
scale_x_log10()
ggplotly(gg)
rm(list = ls())
#### LIBRARIES ####
library(dplyr)
library(forecast)
library(lubridate)
library(xts)
library(ggplot2)
library(imputeTS)
library(TTR)
library(astsa)
#### WD & DATA ####
setwd("C:/Users/David/Google Drive/Github/task-3-1-define-a-data-science-process-dgibert17")
df = read.table("C:/Users/David/Google Drive/Ubiqum/6_EnergyConsumption/power_consumption.txt",
sep = ";",
dec = ".",
col.names = c("date", "time", "global_active_power",
"global_reactive_power", "voltage", "global_intensity",
"kitchen", "laundry_room", "heater_conditioner"),
na.strings = c("?", "-", "NA"),
stringsAsFactors = F,
header = T)
df = df %>%
mutate(global_active_power = (global_active_power*1000)/60,
global_reactive_power = (global_reactive_power*1000)/60,
total_consump = global_active_power+global_reactive_power,
#Las tres en Watt hour (Wh)
total_rest = total_consump -kitchen -laundry_room -heater_conditioner,
#En Watt hour (Wh)
date = as.Date(date, format = "%d/%m/%Y"),
month = as.Date(cut(date, breaks = "month")),
week = as.Date(cut(date, breaks = "week", start.on.monday = T)),
#total rest es el gasto de energia que no contempla submetering
### IMPORTANTE ###
## EL TOTAL REST MUESTRA UN GASTO ENORME QUE NO SABEMOS DE DONDE SALE ##
total_submeter = kitchen + laundry_room + heater_conditioner) %>%
#Gasto de submetering
filter(date > "2006-12-31") %>% # & date < "2010-01-01"
select(-time)
#### NA VALUES BARPLOT ####
barplot(table(df[rowSums(is.na(df)) >= 1 & rowSums(is.na(df)) < length(colnames(df))-1, 1]),
ylab = "Amount of NA values",
xlab = "Date",
main = "Distribution of NA values",
col = "lightblue")
#Distribution of NA per day
tab = table(df[rowSums(is.na(df)) >= 1 & rowSums(is.na(df)) < length(colnames(df))-1, 1])
#### NA VALUES REPLACEMENT AND GROUP DATA BY MONTH SUMMARISED BY SUM ####
df.mean = df %>%
select(-date, -week, -month) %>%
na.mean(option = "mean")
df.mean = cbind(df.mean, month = df$month)
df.mean = df.mean %>%
group_by(month) %>%
summarise_all(sum) %>%
mutate(month = as.yearmon(month))
#### DF-TS ####
total.ts = ts(df.mean$total_consump, frequency = 12, start = 2007)
plot(total.ts, col = "darkblue", lwd = 3, main = "Total energy consumption Time Series")
#### TRAINING & TEST WITH ALL DATA ####
train = df.mean %>%
filter(month > "Dec 2006" & month < "Jan 2010")
test = df.mean %>%
filter(month >= "Jan 2010")
#### TRAINING & TEST TS - TOTAL CONSUMPTION ####
totCons.train.ts = ts(train$total_consump, frequency = 12, start = 2007)
totCons.test.ts = ts(test$total_consump, frequency = 12, start = 2010)
par(mfrow = c(2,1))
plot(totCons.train.ts, col = "darkblue", lwd = 3, main = "Total energy consumption Time Series\nTraining set")
plot(totCons.test.ts, col = "darkblue", lwd = 3, main = "Total energy consumption Time Series\nTest set")
#### TRAINING & TEST TS - ACTIVE POWER ####
active.train.ts = ts(train$global_active_power, frequency = 12, start = 2007)
active.test.ts = ts(test$global_active_power, frequency = 12, start = 2010)
par(mfrow = c(2,1))
plot(active.train.ts, col = "darkblue", lwd = 3, main = "Active energy consumption Time Series\nTraining set")
plot(active.test.ts, col = "darkblue", lwd = 3, main = "Active energy consumption Time Series\nTest set")
#### TRAINING & TEST TS - REACTIVE POWER ####
reactive.train.ts = ts(train$global_reactive_power, frequency = 12, start = 2007)
reactive.test.ts = ts(test$global_reactive_power, frequency = 12, start = 2010)
par(mfrow = c(2,1))
plot(reactive.train.ts, col = "darkblue", lwd = 3, main = "Reactive energy consumption Time Series\nTraining set")
plot(reactive.test.ts, col = "darkblue", lwd = 3, main = "Reactive energy consumption Time Series\nTest set")
#### PLOTING YEARS SEASONALITY BY MONTH ####
ggseasonplot(total.ts, year.labels=TRUE, year.labels.left=TRUE) +
geom_line(size=2) +
geom_point(size=6) +
ylab("Amount consumed") +
ggtitle("Seasonal plot: Energy consumption")
#### FORECASTING MODELS - TOTAL CONSUMPTION ####
total.lm.fit = tslm(formula = totCons.train.ts ~ trend + season)
total.lm.for = forecast(total.lm.fit, h = 12)
total.hw.fit <- HoltWinters(totCons.train.ts)
plot(total.hw.fit)
total.hw.for = forecast(total.hw.fit, h = 12)
total.arima.fit = auto.arima(totCons.train.ts)
total.arima.for = forecast(total.arima.fit, h = 12)
par(mfrow = c(3,1))
plot(total.lm.for)
plot(total.hw.for)
plot(total.arima.for)
#### FORECASTING MODELS - ACTIVE POWER CONSUMPTION ####
active.lm.fit = tslm(formula = active.train.ts ~ trend + season)
active.lm.for = forecast(active.lm.fit, h = 12)
active.hw.fit <- HoltWinters(active.train.ts)
plot(active.hw.fit)
active.hw.for = forecast(active.hw.fit, h = 12)
active.arima.fit = auto.arima(active.train.ts)
active.arima.for = forecast(active.arima.fit, h = 12)
par(mfrow = c(3,1))
plot(active.lm.for)
plot(active.hw.for)
plot(active.arima.for)
#### FORECASTING MODELS - REACTIVE POWER CONSUMPTION ####
reactive.lm.fit = tslm(formula = reactive.train.ts ~ trend + season)
reactive.lm.for = forecast(reactive.lm.fit, h = 12)
reactive.hw.fit <- HoltWinters(reactive.train.ts)
plot(reactive.hw.fit)
reactive.hw.for = forecast(reactive.hw.fit, h = 12)
reactive.arima.fit = auto.arima(reactive.train.ts)
reactive.arima.for = forecast(reactive.arima.fit, h = 12)
par(mfrow = c(3,1))
plot(reactive.lm.for)
plot(reactive.hw.for)
plot(reactive.arima.for)
#### CHECKING THAT THE OUTLIER PEAK COMES FROM WHITE NOISE ####
dec = decompose(total.ts)
par(mfrow = c(3,1))
plot(dec$x, lwd = 3, col = "darkblue", main = "TS", ylab = "", xlab = "")
plot(dec$seasonal, lwd = 3, col = "darkblue", main = "Seasonality", ylab = "", xlab = "")
plot(dec$random, lwd = 3, col = "darkblue", main = "White Noise", ylab = "", xlab = "")
#### PLOTING MODELS - TEST VS TOTAL CONSUMPTION ####
autoplot(totCons.test.ts, ylab="Amount of power consumed", xlab="", main="Total power consumption (active + reactive) forecast") +
geom_line(size = 8) +
geom_point(size = 14) +
autolayer(total.arima.for, PI = F, series = "Arima", size = 2, showgap = F) +
autolayer(total.hw.for, PI = F, series = "Holt Winters", size = 2, showgap = F) +
autolayer(total.lm.for, PI = F, series = "Linear Model", size = 2, showgap = F)
#### PLOTING MODELS - TEST VS ACTIVE CONSUMPTION ####
autoplot(active.test.ts, ylab="Amount of power consumed", xlab="", main = "Active power consumption forecast") +
geom_line(size = 8) +
geom_point(size = 14) +
autolayer(active.arima.for, PI = F, series = "Arima", size = 2, showgap = F) +
autolayer(active.hw.for, PI = F, series = "Holt Winters", size = 2, showgap = F) +
autolayer(active.lm.for, PI = F, series = "Linear Model", size = 2, showgap = F)
#### PLOTING MODELS - TEST VS REACTIVE CONSUMPTION ####
autoplot(reactive.test.ts, ylab="Amount of power consumed", xlab="", main="Reactive power consumption forecast") +
geom_line(size = 8) +
geom_point(size = 14) +
autolayer(reactive.arima.for, PI = F, series = "Arima", size = 2, showgap = F) +
autolayer(reactive.hw.for, PI = F, series = "Holt Winters", size = 2, showgap = F) +
autolayer(reactive.lm.for, PI = F, series = "Linear Model", size = 2, showgap = F)
#### ERROR METRICS FOR MODELS VS TEST DATA - TOTAL CONSUMPTION ####
acc.hw.tot = as.data.frame(accuracy(f = total.hw.for, totCons.test.ts))[2,]
acc.lm.tot = as.data.frame(accuracy(f = total.lm.for, totCons.test.ts))[2,]
acc.arima.tot = as.data.frame(accuracy(f = total.arima.for, totCons.test.ts))[2,]
error.total = rbind(acc.hw.tot, acc.lm.tot, acc.arima.tot)
rownames(error.total) <- c("Holt Winters", "Linear Model", "ARIMA")
#### ERROR METRICS FOR MODELS VS TEST DATA - ACTIVE CONSUMPTION ####
acc.hw.active = as.data.frame(accuracy(f = active.hw.for, active.test.ts))[2,]
acc.lm.active = as.data.frame(accuracy(f = active.lm.for, active.test.ts))[2,]
acc.arima.active = as.data.frame(accuracy(f = active.arima.for, active.test.ts))[2,]
error.active = rbind(acc.hw.active, acc.lm.active, acc.arima.active)
rownames(error.active) <- c("Holt Winters", "Linear Model", "ARIMA")
#### ERROR METRICS FOR MODELS VS TEST DATA - ACTIVE CONSUMPTION ####
acc.hw.reactive = as.data.frame(accuracy(f = reactive.hw.for, reactive.test.ts))[2,]
acc.lm.reactive = as.data.frame(accuracy(f = reactive.lm.for, reactive.test.ts))[2,]
acc.arima.reactive = as.data.frame(accuracy(f = reactive.arima.for, reactive.test.ts))[2,]
error.reactive = rbind(acc.hw.reactive, acc.lm.reactive, acc.arima.reactive)
rownames(error.reactive) <- c("Holt Winters", "Linear Model", "ARIMA")
error.total
error.active
error.reactive
#### FORECAST CON MEJOR MODELO - TOTAL CONSUMPTION ####
#### FORECAST CON MEJOR MODELO - ACTIVE CONSUMPTION ####
#### FORECAST CON MEJOR MODELO - REACTIVE CONSUMPTION ####
